# ğŸ¥ Patient Communication Assistant

An AI-powered RAG (Retrieval-Augmented Generation) application that transforms complex medical documents into patient-friendly explanations at an 8th-grade reading level.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![React](https://img.shields.io/badge/React-18.2-61DAFB.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688.svg)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—_HuggingFace-Transformers-yellow.svg)

## ğŸ¯ Problem Statement

Patients often struggle to understand complex medical discharge instructions, medication guides, and doctor notes. Medical jargon and technical language create barriers to proper self-care, leading to:
- Medication non-adherence
- Missed follow-up appointments
- Preventable hospital readmissions
- Poor health outcomes

## ğŸ’¡ Solution

A two-stage RAG pipeline that:
1. **Ingests** medical PDFs with intelligent chunking
2. **Retrieves** relevant information using semantic search
3. **Simplifies** complex text to an 8th-grade reading level
4. **Validates** output with automated readability scoring

## âœ¨ Features

- **PDF Document Ingestion**: Upload discharge summaries, medication guides, and clinical notes
- **Intelligent Chunking**: Section-aware text splitting optimized for medical documents
- **Semantic Search**: Vector similarity search using Sentence Transformers embeddings
- **AI Simplification**: Two-stage LLM pipeline for text simplification
- **Readability Scoring**: Automated Flesch-Kincaid, Gunning Fog, SMOG, and Coleman-Liau analysis
- **Interactive Q&A**: Ask questions about uploaded documents in natural language
- **Modern Web Interface**: Responsive React frontend with real-time feedback

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Upload    â”‚â”€â”€â”€â”€â–¶â”‚   Ingestion     â”‚â”€â”€â”€â”€â–¶â”‚  Vector Store   â”‚
â”‚                 â”‚     â”‚  (PyPDF/Plumber)â”‚     â”‚   (ChromaDB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Simplified     â”‚â—€â”€â”€â”€â”€â”‚   Generation    â”‚â—€â”€â”€â”€â”€â”‚    Retrieval    â”‚
â”‚   Response      â”‚     â”‚ (Phi-3/Mistral) â”‚     â”‚ (Semantic Searchâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Readability  â”‚
                        â”‚   Validation  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - High-performance async API framework
- **ChromaDB** - Vector database for semantic search
- **Sentence Transformers** - Open-source embeddings (all-MiniLM-L6-v2)
- **Hugging Face Transformers** - LLM inference (Phi-3, Mistral, Llama)
- **PyPDF2 / pdfplumber** - PDF text extraction
- **textstat** - Readability metrics calculation

### Frontend
- **React 18** - Component-based UI
- **Tailwind CSS** - Utility-first styling
- **Vite** - Fast build tooling
- **Lucide React** - Icon library

## ğŸ“ Project Structure

```
patient-comm-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration settings
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # PDF extraction & preprocessing
â”‚   â”‚   â””â”€â”€ chunker.py          # Medical-aware text chunking
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Sentence Transformer wrapper
â”‚   â”‚   â””â”€â”€ vector_store.py     # ChromaDB operations
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ simplifier.py       # LLM simplification pipeline
â”‚   â”‚   â””â”€â”€ prompts.py          # Prompt templates
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ readability.py      # Readability scoring
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main React component
â”‚   â”‚   â”œâ”€â”€ main.jsx            # Entry point
â”‚   â”‚   â””â”€â”€ index.css           # Tailwind imports
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_docs/            # Sample PDFs for testing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- 8GB+ RAM (for LLM inference)

### Backend Setup

```bash
# Clone repository
git clone https://github.com/yourusername/patient-comm-assistant.git
cd patient-comm-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start backend server
uvicorn app.main:app --reload
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

### Access Application
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| GET | `/stats` | Index statistics |
| POST | `/upload` | Upload PDF document |
| POST | `/ask` | Ask question (RAG) |
| POST | `/simplify` | Simplify text (LLM) |
| POST | `/readability` | Analyze readability |
| DELETE | `/clear` | Clear all documents |

## ğŸ“ˆ Performance Metrics

- **Readability Improvement**: Average 12+ grade level reduction
- **Flesch Ease Improvement**: +60-80 points (from negative to 70+)
- **Embedding Latency**: <100ms for query embedding
- **Retrieval Latency**: <50ms for top-k search

## ğŸ”® Future Enhancements

- [ ] PubMedBERT embeddings for improved medical domain relevance
- [ ] Multi-language support for diverse patient populations
- [ ] Speech-to-text for accessibility
- [ ] Integration with EHR systems (FHIR API)
- [ ] Confidence scoring for generated responses

## ğŸ“„ License

MIT License - feel free to use for personal or commercial projects.

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or submit a pull request.